---
title: "SoloLearn Data Science"
author: "Ken Harmon"
date: "`r format(Sys.time(), '%Y %B %d')`"
output:
  html_document:
    keep_md: yes
    code_folding: hide
    fig_height: 6
    fig_width: 12
    fig_align: center
  pdf_document: default
editor_options:
  chunk_output_type: console
---
 
https://www.sololearn.com/Play/machine-learning

# {.tabset .tabset-fade}

```{r, echo=FALSE}
library(reticulate)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
knitr::knit_engines$set(python = reticulate::eng_python)
reticulate::repl_python()

```

```{r}
#py_install("spyder")
#py_install("sqlalchemy")
```

https://www.sololearn.com/Play/data-science

Welcome to Data Science

Congratulations on taking a big step toward becoming a data scientist!
In addition to working through this course, be sure to take advantage of all of the learning support available to you on SoloLearn, including the daily tips, Try it Yourself practices, code coach challenges, code playground, and engagement with our amazing learner community. We love to hear from you, so please leave comments and feedback as you learn with us.

What is Data Science?

There are many use cases in business for data science including finding a better housing price prediction algorithm for Zillow, finding key attributes associated with wine quality, and building a recommendation system to increase the click-through-rate for Amazon.

Extracting insights from seemingly random data, data science normally involves collecting data, cleaning data, performing exploratory data analysis, building and evaluating machine learning models, and communicating insights to stakeholders.

Why Python?

In this Introduction to Data Science course we’re learning data science with Python. As a general-purpose programming language, Python is now the most popular programming language in data science. It’s easy to use, has great community support, and integrates well with other frameworks (e.g., web applications) in an engineering environment.

This course focuses on exploratory data analysis with three fundamental Python libraries: numpy, pandas and matplotlib. The machine learning library scikit-learn will be covered as well.

In the later modules, we will be predicting home values using linear regression, identifying classes of iris with classification algorithms, and finding clusters within wines, just a few examples of what we can do in data science.
In data science, there are other popular programming languages, such as R, which has an edge in statistical modeling.

Numerical Data

Datasets come from a wide range of sources and formats: it could be collections of numerical measurements, text corpus, images, audio clips, or basically anything. No matter the format, the first step in data science is to transform it into arrays of numbers.

We collected 45 U.S. president heights in centimeters in chronological order and stored them in a list, a built-in data type in python.


```{python}
heights = [189, 170, 189, 163, 183, 171, 185, 168, 173, 183, 173, 173, 175, 178, 183, 193, 178, 173, 174, 183, 183, 180, 168, 180, 170, 178, 182, 180, 183, 178, 182, 188, 175, 179, 183, 193, 182, 183, 177, 185, 188, 188, 182, 185, 191]
```

In this example, George Washington was the first president, and his height was 189 cm.

If we wanted to know how many presidents are taller than 188cm, we could iterate through the list, compare each element against 188, and increase the count by 1 as the criteria is met.

```{python}
cnt = 0
for height in heights:
  if height > 188:
    cnt +=1
print(cnt)
```

This shows that there are five presidents who are taller than 188 cm.

Introduction to Numpy

Numpy (short for Numerical Python) allows us to find the answer to how many presidents are taller than 188cm with ease. Below we show how to use the library and start with the basic object in numpy.

```{python}
import numpy as np
heights_arr = np.array(heights)
print((heights_arr > 188).sum())
```

The import statement allows us to access the functions and modules inside the numpy library. The library will be used frequently, so by convention numpy is imported under a shorter name, np. The second line is to convert the list into a numpy array object, via np.array(), that tools provided in numpy can work with. The last line provides a simple and natural solution, enabled by numpy, to the original question.

As our datasets grow larger and more complicated, numpy allows us the use of a more efficient and for-loop-free method to manipulate and analyze our data. Our dataset example in this module will include the US Presidents' height, age and party.

Size and Shape

An array class in Numpy is called an ndarray or n-dimensional array. We can use this to count the number of presidents in heights_arr, use attribute numpy.ndarray.size:

```{python}
heights_arr.size
```

Note that once an array is created in numpy, its size cannot be changed.

Size tells us how big the array is, shape tells us the dimension. To get current shape of an array use attribute shape:

```{python}
heights_arr.shape
```

The output is a tuple, recall that the built-in data type tuple is immutable whereas a list is mutable, containing a single value, indicating that there is only one dimension, i.e., axis 0. Along axis 0, there are 45 elements (one for each president) Here, heights_arr is a 1d array.
Attribute size in numpy is similar to the built-in method len in python that is used to compute the length of iterable python objects like str, list, dict, etc.

Reshape

Other data we have collected includes the ages of the presidents:


```{python}
ages = [57, 61, 57, 57, 58, 57, 61, 54, 68, 51, 49, 64, 50, 48, 65, 52, 56, 46, 54, 49, 51, 47, 55, 55, 54, 42, 51, 56, 55, 51, 54, 51, 60, 62, 43, 55, 56, 61, 52, 69, 64, 46, 54, 47, 70]
```

Since both heights and ages are all about the same presidents, we can combine them:

```{python}
heights_and_ages = heights + ages 
# convert a list to a numpy array
heights_and_ages_arr = np.array(heights_and_ages)
heights_and_ages_arr.shape
```

This produces one long array. It would be clearer if we could align height and age for each president and reorganize the data into a 2 by 45 matrix where the first row contains all heights and the second row contains ages. To achieve this, a new array can be created by calling numpy.ndarray.reshape with new dimensions specified in a tuple:

```{python}
heights_and_ages_arr.reshape((2,45))
```

The reshaped array is now a 2darray, yet note that the original array is not changed. We can reshape an array in multiple ways, as long as the size of the reshaped array matches that of the original.

```{python}
heights_and_ages_arr = heights_and_ages_arr.reshape((2,45))
```

Data Type

Another characteristic about numpy array is that it is homogeneous, meaning each element must be of the same data type.

For example, in heights_arr, we recorded all heights in whole numbers; thus each element is stored as an integer in the array. To check the data type, use numpy.ndarray.dtype

```{python}
heights_arr.dtype
```

If we mixed a float number in, say, the first element is 189.0 instead of 189

```{python}
heights_float = [189.0, 170, 189, 163, 183, 171, 185, 168, 173, 183, 173, 173, 175, 178, 183, 193, 178, 173, 174, 183, 183, 180, 168, 180, 170, 178, 182, 180, 183, 178, 182, 188, 175, 179, 183, 193, 182, 183, 177, 185, 188, 188, 182, 185, 191]
```

Then after converting the list into an array, we’d see all other numbers are coerced into floats:

```{python}
heights_float_arr = np.array(heights_float)
heights_float_arr
heights_float_arr.dtype
```

Indexing

We can use array indexing to select individual elements from arrays. Like Python lists, numpy index starts from 0.

To access the height of the 3rd president Thomas Jefferson in the 1darray 'heights_arr':

```{python}
heights_arr[2]
```

In a 2darray, there are two axes, axis 0 and 1. Axis 0 runs downward down the rows whereas axis 1 runs horizontally across the columns.

In the 2darrary heights_and_ages_arr, recall that its dimensions are (2, 45). To find Thomas Jefferson’s age at the beginning of his presidency you would need to access the second row where ages are stored:

```{python}
heights_and_ages_arr[1,2]
```

Slicing

What if we want to inspect the first three elements from the first row in a 2darray? We use ":" to select all the elements from the index up to but not including the ending index. This is called slicing.

```{python}
heights_and_ages_arr[0, 0:3]
```

When the starting index is 0, we can omit it as shown below:

```{python}
heights_and_ages_arr[0, :3]
```

What if we’d like to see the entire third column? Specify this by using a ":" as follows

```{python}
heights_and_ages_arr[:, 3]
```

Assigning Single Values

Sometimes you need to change the values of particular elements in the array. For example, we noticed the fourth entry in the heights_arr was incorrect, it should be 165 instead of 163, we can re-assign the correct number by:

```{python}
heights_arr[3] = 165

heights_arr
```

In a 2darray, single values can be assigned easily. You can use indexing for one element. For example, change the fourth entry in heights_arr to 165:

```{python}
heights_and_ages_arr[0, 3] = 165
heights_and_ages_arr
```

Or we can use slicing for multiple elements. For example, to replace the first row by its mean 180 in heights_and_ages_arr:

```{python}
heights_and_ages_arr[0,:] = 180
heights_and_ages_arr
```

We can also combine slicing to change any subset of the array. For example, to reassign 0 to the left upper corner:

```{python}
heights_and_ages_arr[:2, :2] = 0
heights_and_ages_arr
```

Assigning an Array to an Array

In addition, a 1darray or a 2darry can be assigned to a subset of another 2darray, as long as their shapes match. Recall the 2darray heights_and_ages_arr:

```{python}
heights_and_ages_arr
```

If we want to update both height and age of the first president with new data, we can supply the data in a list:

```{python}
heights_and_ages_arr[:, 0] = [190, 58]
heights_and_ages_arr
```

We can also update data in a subarray with a numpy array as such:

```{python}
new_record = np.array([[180, 183, 190], [54, 50, 69]])
heights_and_ages_arr[:, 42:] = new_record
heights_and_ages_arr
```

Combining Two Arrays

Oftentime we obtain data stored in different arrays and we need to combine them into one to keep it in one place. For example, instead of having the ages stored in a list, it could be stored in a 2darray:

```{python}
ages_arr.shape
ages_arr[:3,]
```

If we reshape the heights_arr to (45,1), the same as 'ages_arr', we can stack them horizontally (by column) to get a 2darray using 'hstack':

```{python}
heights_arr = np.array(heights)
heights_arr = heights_arr.reshape((45,1))
ages_arr = np.array(ages)
ages_arr = ages_arr.reshape((45,1))
height_age_arr = np.hstack((heights_arr, ages_arr))
height_age_arr.shape
height_age_arr[:3,]
```

Now height_age_arr has both heights and ages for the presidents, each column corresponds to the height and age of one president.

Similarly, if we want to combine the arrays vertically (by row), we can use 'vstack'.

```{python}
heights_arr = heights_arr.reshape((1,45))
ages_arr = ages_arr.reshape((1,45))

height_age_arr = np.vstack((heights_arr, ages_arr))
height_age_arr.shape
height_age_arr[:,:3]
```

Concatenate

More generally, we can use the function numpy.concatenate. If we want to concatenate, link together, two arrays along rows, then pass 'axis = 1' to achieve the same result as using numpy.hstack; and pass 'axis = 0' if you want to combine arrays vertically.

In the example from the previous part, we were using hstack to combine two arrays horizontally, instead:

```{python}
height_age_arr = np.concatenate((heights_arr, ages_arr), axis=1)
```

Also you can get the same result as using vstack:

```{python}
height_age_arr = np.concatenate((heights_arr, ages_arr), axis=0) 
```

Mathematical Operations on Arrays

Performing mathematical operations on arrays is straightforward. For instance, to convert the heights from centimeters to feet, knowing that 1 centimeter is equal to 0.0328084 feet, we can use multiplication:

```{python}
height_age_arr[:,0]*0.0328084
```

Numpy Array Method

In addition, there are several methods in numpy to perform more complex calculations on arrays. For example, the sum() method finds the sum of all the elements in an array:

```{python}
height_age_arr.sum()
```

The sum of all heights and ages is 10575. In order to sum all heights and sum all ages separately, we can specify axis=0 to calculate the sum across the rows, that is, it computes the sum for each column, or column sum. On the other hand, to obtain the row sums specify axis=1. In this example, we want to calculate the total sum of heights and ages, respectively:

```{python}
height_age_arr.sum(axis=1)
```

The output is the row sums: heights of all presidents (i.e., the first row) add up to 8100, and the sum of ages (i.e., the second row) is 2475.

Comparisons

In practicing data science, we often encounter comparisons to identify rows that match certain values. We can use operations including "<", ">", ">=", "<=", and "==" to do so. For example, in the height_age_arr dataset, we might be interested in only those presidents who started their presidency younger than 55 years old.

```{python}
import numpy as np

heights_arr = np.array([189, 170, 189, 163, 183, 171, 185, 168, 173, 183, 173, 173, 175, 178, 183, 193, 178, 173, 174, 183, 183, 180, 168, 180, 170, 178, 182, 180, 183, 178, 182, 188, 175, 179, 183, 193, 182, 183, 177, 185, 188, 188, 182, 185, 191])
ages_arr = np.array([57, 61, 57, 57, 58, 57, 61, 54, 68, 51, 49, 64, 50, 48, 65, 52, 56, 46, 54, 49, 51, 47, 55, 55, 54, 42, 51, 56, 55, 51, 54, 51, 60, 62, 43, 55, 56, 61, 52, 69, 64, 46, 54, 47, 70]).reshape((-1,1))

heights_arr = heights_arr.reshape((45,1))
height_age_arr = np.hstack((heights_arr, ages_arr))

print(height_age_arr[:, 1] < 55)
```

The output is a 1darray with boolean values that indicates which presidents meet the criteria. If we are only interested in which presidents started their presidency at 51 years of age, we can use "==" instead.

```{python}
height_age_arr[:, 1] == 51
```

Mask & Subsetting

Now that rows matching certain criteria can be identified, a subset of the data can be found. For example, instead of the entire dataset, we want only tall presidents, that is, those presidents whose height is greater than or equal to 182 cm. We first create a mask, 1darray with boolean values:

```{python}
mask = height_age_arr[:, 0] >= 182
mask.sum()
```

Then pass it to the first axis of `height_age_arr` to filter presidents who don’t meet the criteria:

```{python}
tall_presidents = height_age_arr[mask, ]
tall_presidents.shape
```

This is a subarray of height_age_arr, and all presidents in tall_presidents were at least 182cm tall.

Multiple Criteria

We can create a mask satisfying more than one criteria. For example, in addition to height, we want to find those presidents that were 50 years old or younger at the start of their presidency. To achieve this, we use & to separate the conditions and each condition is encapsulated with parentheses "()" as shown below:

```{python}
mask = (height_age_arr[:, 0]>=182) & (height_age_arr[:,1]<=50)
height_age_arr[mask,]
```

The results show us that there are four presidents who satisfy both conditions.

Pandas vs. Numpy

What if we want to inspect the data on Abraham Lincoln in 'height_age_arr' but cannot remember his integer position. Is there a convenient way to access the data by indexing the name of the president like:

```{python}
print(height_age_arr['Abraham Lincoln'])
```

Unfortunately, we will receive an error message. However, it is possible to do this in pandas. The pandas library is built on top of numpy, meaning a lot of features, methods, and functions are shared.

By convention, import the library under a short name "pd":

```{python}
import pandas as pd
```

Series

The Series is one building block in pandas. Pandas Series is a one-dimensional labeled array that can hold data of any type (integer, string, float, python objects, etc.), similar to a column in an excel spreadsheet. The axis labels are collectively called index.

If we are given a bag of letters a, b, and c, and count how many of each we have, we find that there are 1 a, 2 b’s, and 3 c’s. We could create a Series by supplying a list of counts and their corresponding labels:

```{python}
pd.Series([1, 2, 3], index=['a', 'b', 'c']) # with index
```

Alternatively, the values can be a numpy array:

```{python}
pd.Series(np.array([1, 2, 3]), index=['a', 'b', 'c']) # from a 1darray
```

Or, we could use a dictionary to specify the index with keys:

```{python}
pd.Series({'a': 1, 'b': 2, 'c':3}) # from a dict
```

If we don’t specify the index, by default, the index would be the integer positions starting from 0.

In a Series, we can access the value by its index directly:

```{python}
series = pd.Series({'a': 1, 'b': 2, 'c':3})
series['a']
```

Accessing the value by its index, rather than the integer position comes in handy when the dataset is of thousands, if not millions, of rows. Series is the building block for the DataFrame we will introduce next.

DataFrames

In data science, data is usually more than one-dimensional, and of different data types; thus Series is not sufficient. DataFrames are 2darrays with both row and column labels. One way to create a DataFrame from scratch is to pass in a dict. For example, this week, we sold 3 bottles of red wine to Adam, 6 to Bob, and 5 to Charles. We sold 5 bottles of white wine to Adam, 0 to Bob and 10 to Charles. We can organize the data into a DataFrame by creating a dict 'wine_dict' with the number of bottles of each wine type we sold, then pass it along with the customer names as index to create a DataFrame 'sales'.

```{python}
wine_dict = {
  'red_wine': [3, 6, 5], 
  'white_wine':[5, 0, 10]
}
sales = pd.DataFrame(wine_dict, index=["adam", "bob", "charles"])
```

Think of DataFrame as a collection of the Series. Here, sales consists of two Series, one named under "red_wine", the other "white_wine", thus, we can access each series by calling its name:

```{python}
sales['white_wine']
```

Inspect a DataFrame - Shape and Size

Let’s take a look at a new DataFrame, in addition to heights and ages of the presidents, there is information on the order, names and parties. The DataFrame presidents_df is read from a CSV file as follows. Note that index is set to be the names of presidents.

```{python}
import pandas as pd
presidents_df = pd.read_csv("president_heights_party.csv", index_col='name')
```

Similar to numpy, to get the dimensions of a DataFrame, use .shape.

```{python}
presidents_df.shape
```

There are 45 rows and 4 columns in this DataFrame. To get the number of rows we can access the first element in the tuple.

```{python}
presidents_df.shape[0]
```

Size also works on DataFrame to return an integer representing the number of elements in this object.

```{python}
presidents_df.size
```

Inspect a DataFrame - Head and Tail

Instead of looking at the entire dataset, we can just take a peep. To see the first few lines in a DataFrame, use .head(); if we don’t specify n (the number of lines), by default, it displays the first five rows. Here we want to see the top 3 rows.

```{python}
presidents_df.head(n=3)
```

In presidents_df, the index is the name of the president, there are four columns: order, age, height, and party. Similarly, if we want to see the last few rows, we can use .tail(), the default is also five rows.

```{python}
presidents_df.tail()
```

Inspect a DataFrame - Info

Use .info() to get an overview of the DataFrame. Its output includes index, column names, count of non-null values, dtypes, and memory usage.

```{python}
presidents_df.info()
```

The dtype for order, age, and height is integers, while party is an object. The count of non-null values in each column is the same as the number of rows, indicating no missing values.

Rows with .loc

Instead of memorizing the integer positions to locate the order, age, height, and party information of Abraham Lincoln, with DataFrame, we can access it by the name using .loc:

```{python}
presidents_df.loc['Abraham Lincoln']
```

The result is a pandas Series of shape (4,).

```{python}
type(presidents_df.loc['Abraham Lincoln'])

presidents_df.loc['Abraham Lincoln'].shape
```

We can also slice by index. Say we are interested in gathering information on all of the presidents between Abraham Lincoln and Ulysses S. Grant:

```{python}
presidents_df.loc['Abraham Lincoln':'Ulysses S. Grant']
```

Rows with .iloc

Alternatively, if we do know the integer position(s), we can use .iloc to access the row(s).

```{python}
presidents_df.iloc[15]
```

To gather information from the 16th to 18th presidents, we can then:

```{python}
presidents_df.iloc[15:18]
```

Columns

We can retrieve an entire column from presidents_df by name. First we access all the column names:

```{python}
presidents_df.columns
```

Which returns an index object containing all column names. Then we can access the column height by:

```{python}
presidents_df['height']
presidents_df['height'].shape
```

Which returns a Series containing heights from all U.S. presidents.

To select multiple columns, we pass the names in a list, resulting in a DataFrame. Remember, we can use .head() to access the first 3 rows as shown below:

```{python}
presidents_df[['height','age']].head(n=3)
```

More with .loc

If we wanted to access columns order, age, and height, we can do it with .loc. .loc allows us to access any of the columns. For example, if we wanted to access columns from order through height for the first three presidents:

```{python}
presidents_df.loc[:, 'order':'height'].head(n=3)
```

Min / Max / Mean

It’s not practical to print out an entire dataset with a large sample size. Instead, we want to summarize and characterize sample data using only a few values. Summary statistics include measures of location and measures of spread. Measures of location are quantities that represent the average value of a variable while measures of spread represent how similar or dissimilar the values of a variable are.

Measures of Location - Minimum, Maximum, Mean

Measures of Spread - Range, Variance, Standard Deviation

The simplest summary statistics, which are measures of location, include the minimum, the smallest number:

```{python}
presidents_df.min()
presidents_df.max()
presidents_df.mean()
presidents_df.median()
presidents_df.quantile(q=.25)
```

Recall the arithmetic mean is the sum of the elements divided by the number of elements, in python 3.x, division of integers results in a float number.

Once the minimum and maximum are known, we can determine the range, a measure of spread. For example, the height for all U.S. presidents ranges from 163 -- 193 cm.

The mean tells us where the data is centered. For instance, the average age at the start of the presidency is 54.71 years. Note that mean() can only operate on the numeric values, thus the column 'party' was omitted.

Quantiles

Quantiles are cut points dividing the range of the data into continuous intervals with an equal number of observations. Median is the only cut point in 2-quantiles, such that 50% of the data is below the median with the other half above it.

Quartiles let us quickly divide a set of data into four groups, making it easy to see which of the four groups a particular data point is in. Quartiles are then 4-quantiles, that is, 25% of the data are between the minimum and first quartile, the next is 25% between the first quartile and median, the next 25% is between the median and the third quartile, and the last 25% of the data lies between the third quartile and the maximum.

```{python}
presidents_df['age'].quantile([0.25, 0.5, 0.75, 1])
```

Here 25% of presidents started their presidency at 51 years old or younger, while half started their presidency at 55 years old or younger.

Mean and median are usually not of the same value, unless the data is perfectly symmetric. The mean is the average of all the numbers added together and divided by the amount of numbers added. The median is the value separating the higher half from the lower half of the data sample. In the age data, the mean is close to its median, this implies that the data might be symmetric.

```{python}
presidents_df['age'].mean()

presidents_df['age'].median()
```

Variance and Standard Deviation

In probability and statistics, variance is the mean squared deviation of each data point from the mean of the entire dataset.

You can think of it as how far apart a set of numbers are spread out from their average value. Standard deviation (std) is the square root of variance. A high std implies a large spread, and a low std indicates a small spread, or most points are close to the mean.

In one extreme example, the data consists of all constant 2, there is no variation, thus the variation is 0.0, so is its std:

```{python}
const = pd.Series([2, 2, 2])
const.var()
const.std()
```

Lets consider another example:
[2, 3, 4] 

The mean of [2,3,4] is (2+3+4)/3 = 3.0, and its variation is (2-3)^2 + (3-3)^2 + (4-3)^2 = 1+0+1 = 2. Note that in Python, .var() will return the variance divided by N-1 where N is the length of the data, the output is then 2/(3-1) = 1.

```{python}
dat = pd.Series([2, 3, 4])
dat.mean()
dat.var()
dat.std()
```

For the ages of the presidents:

```{python}
presidents_df['age'].var()
presidents_df['age'].std()
```

We can apply std on the entire DataFrame to get column-wise standard deviation.

```{python}
presidents_df.std()
```

describe()

describe() prints out almost all of the summary statistics mentioned previously except for the variance. In addition, it counts all non-null values of each column.

```{python}
presidents_df['age'].describe()
presidents_df.describe()
```

From the output we can see that there are 45 non-null data points of ages, with a mean 55 and std 6.60. The ages range from 42 to 70 with a median 55. Its first and third quartiles are 51 and 58, respectively. Now we have an overall description of all age data. In addition to being applied to a series, describe() can be applied to a DataFrame with multiple columns.

As the count (=45) suggests, there are no null values in any of the three columns. Order is simply an index from 1 to 45. Interestingly, both age and height lie in the interval of roughly the same length, 70-42 = 28 for age while 193-163 = 30 for height. Also both features are of similar standard deviations, indicating a similar spread of the data.

Categorical Variable

The fourth column 'party' was omitted in the output of .describe() because it is a categorical variable. A categorical variable is one that takes on a single value from a limited set of categories. It doesn’t make sense to calculate the mean of democratic, republican, federalist, and other parties. We can check the unique values and corresponding frequency by using .value_counts():

```{python}
presidents_df['party'].value_counts()
```

We can also call .describe() to see that there are 45 non-null values, 7 unique parties, the most frequent party is republican, with a total of 19 presidents belonging to this party.

```{python}
presidents_df['party'].describe()
```

Groupby

Summary statistics on an entire dataset provides a good overall view, but often we’re interested in some calculation conditional upon a given label or category. For example, what is the average height conditional of the presidents party?

To find the value based on a condition, we can use the groupby operation. Think of groupby doing three steps: split, apply, and combine. The split step breaks the DataFrame into multiple DataFrames based on the value of the specified key; the apply step is to perform the operation inside each smaller DataFrame; the last step combines the pieces back into the larger DataFrame.

```{python}
presidents_df.groupby('party')
```

The .groupby("party") returns a DataFrameGroupBy object, not a set of DataFrames. To produce a result, apply an aggregate (.mean()) to this DataFrameGroupBy object:

```{python}
presidents_df.groupby('party').mean()
```

Aggregation

We can also perform multiple operations on the groupby object using .agg() method. It takes a string, a function, or a list thereof. For example, we would like to obtain the min, median, and max values of heights grouped by party:

```{python}
presidents_df.groupby('party')['height'].agg(['min', np.median, max])
```

From the output we can see, the heights of the democratic presidents range from 168 cm to 193 cm, with a median at 180 cm.

Often time we are interested in different summary statistics for multiple columns. For instance, we would like to check the median and mean of heights, but minimum and maximum for ages, grouped by party. In this case, we can pass a dict with key indicate the column name, and value indicate the functions:

```{python}
presidents_df.groupby('party').agg({"height": [np.median, np.mean],"age": [min, max]})
```

Line Plot

Let’s start with a beautiful wave function, sine function, sin(x), where x ranges from 0 to 10. We need to generate the sequence along the x-axis, an evenly spaced array, via linspace().

```{python}
import numpy as np
x = np.linspace(0,10,1000) 
# x is a 1000 evenly spaced numbers from 0 to 10
```

The second line generates an evenly spaced sequence of 1000 numbers o 0 to 10. You can view it as tides go up and down over time and the height of the tides are obtained by the sin function.

```{python}
y = np.sin(x)
```

To plot, as before, we first create the figure and axes objects.

```{python}
import matplotlib.pyplot as plt
fig = plt.figure()
ax = plt.axes()
```

We now make a plot directly from the Axes, "ax.plot()"; by default, it generates a Line2D object. To show the plot, we need to call show().

```{python}
ax.plot(x, y)
plt.show()
```

Alternatively, we can use the pylab interface and let the figure and axes be created for us in the background.

```{python}
plt.plot(x, y)
plt.show()
```

```{python}
x = np.linspace(0, 30, 1000)
plt.cla()
plt.plot(x, np.cos(x))
plt.show()
```

Labels and Titles

One critical component of every figure is the figure title. The job of the title is to accurately communicate what the figure is about. In addition, axes need titles, or more commonly referred to as axis labels. The axis labels explain what the plotted data values are. We can specify the x and y axis labels and a title using plt.xlabel(), plt.ylabel() and plt.title().

```{python}
x = np.linspace(0,10,1000) # 1darray of length 1000
y = np.sin(x)
plt.cla()
plt.plot(x, y)
plt.xlabel('x')
plt.ylabel('y')
plt.title('function sin(x)')
plt.show()
```

Multiple Lines

Usually there are various datasets of similar nature, and we would like to compare them and observe the differences. We can plot multiple lines on the same figure. Say, the sin function capture the tides on the east coast and cos function capture the tides on the west coast at the same time, we can plot them both on the same figure by calling the .plot() function multiple times.

```{python}
x = np.linspace(0,10,1000) # 1darray of length 1000
plt.cla()
plt.plot(x, np.sin(x))
plt.plot(x, np.cos(x))
plt.show()
```

Colors and line styles can be specified to differentiate lines:

```{python}
x = np.linspace(0,10,1000) # 1darray of length 1000
plt.cla()
plt.plot(x, np.sin(x), color='k')
plt.plot(x, np.cos(x), color='r', linestyle ='--')
plt.show()
```

Note that we specified basic colors using a single letter, that is, k for black and r for red. More examples include b for blue, g for green, c for cyan, etc. For more details on the use of colors in matplotlib, refer to its documentation.
https://matplotlib.org/2.0.2/api/colors_api.html

Legend

When there are multiple lines on a single axes, it’s often useful to create a plot legend labeling each line. We can use the method plt.legend(), in conjunction with specifying labels in the plt.plot()

```{python}
x = np.linspace(0,10,1000) # 1darray of length 1000
plt.cla()
plt.plot(x, np.sin(x), 'k:', label='sin(x)')
plt.plot(x, np.cos(x), 'r--', label='cos(x)')
plt.legend()
plt.show()
```

Note here we use 'k:' to indicate the line of sin function to be black (indicated by k) and dotted (indicated by :). Line style and color codes can be combined into a single non-keyword argument in the plt.plot() function.

https://matplotlib.org/3.1.3/tutorials/index.html#colors












